{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook for Model Training\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(annotations_path, images_folder):\n",
    "    annotations = pd.read_csv(annotations_path)\n",
    "    image_paths = [os.path.join(images_folder, f\"{row['image_id']}.jpg\") for _, row in annotations.iterrows()]\n",
    "    return image_paths, annotations\n",
    "\n",
    "# Function to preprocess the dataset\n",
    "def preprocess_dataset(image_paths, annotations, label_map_path):\n",
    "    label_map = label_map_util.load_labelmap(label_map_path)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    annotations['class_int'] = annotations['class'].apply(lambda x: next(item['id'] for item in category_index if item['name'] == x))\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# Function to create a TensorFlow Dataset\n",
    "def create_tf_dataset(image_paths, annotations):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, annotations))\n",
    "    dataset = dataset.map(load_image_and_annotations, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Function to load an image and its annotations\n",
    "def load_image_and_annotations(image_path, annotations):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))  # Adjust the size as needed\n",
    "\n",
    "    # Preprocess annotations, convert to TensorFlow compatible format\n",
    "    # ...\n",
    "\n",
    "    return image, annotations\n",
    "\n",
    "# Function to create and compile the detection model\n",
    "def create_detection_model(num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Paths\n",
    "annotations_path = '\n",
    "images_folder = '\n",
    "label_map_path = '\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "image_paths, annotations = load_dataset(annotations_path, images_folder)\n",
    "annotations = preprocess_dataset(image_paths, annotations, label_map_path)\n",
    "\n",
    "# Create TensorFlow Dataset\n",
    "batch_size = 32\n",
    "train_dataset = create_tf_dataset(image_paths, annotations).batch(batch_size)\n",
    "\n",
    "# Create and compile the detection model\n",
    "num_classes = 1  # Adjust based on your dataset\n",
    "detection_model = create_detection_model(num_classes)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10  # Adjust as needed\n",
    "detection_model.fit(train_dataset, epochs=epochs)\n",
    "\n",
    "# Save the trained model\n",
    "output_model_path = '/models/detection_model.h5'\n",
    "tf.saved_model.save(detection_model, output_model_path)\n",
    "\n",
    "print(\"Model training completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
